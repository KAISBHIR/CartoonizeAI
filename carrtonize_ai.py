# -*- coding: utf-8 -*-
"""CARRTONIZE_AI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I72XPZfPDDs1Y5wWic6arIUOaFbco4bT
"""

import cv2
cv2.__version__

import numpy as np
from google.colab.patches import cv2_imshow
from google.colab import files

def read_file(filename):
  img = cv2.imread(filename)
  cv2_imshow(img)
  return img

uploaded = files.upload()
filename = next(iter(uploaded))
img = read_file(filename)

def edge_mask(img, line_size, blur_value):
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)   # transform the image into grayscale
  gray_blur = cv2.medianBlur(gray, blur_value)   # reduce the noise of the blurred grayscale image ( if blurvalue >>> then fewer black noises appear in the image )
  edges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value) # detect the edge in an image ( if linesize >>> then the thicker edges that will be highlight in the image)
  return edges

line_size = 7
blur_value = 7
edges = edge_mask(img, line_size, blur_value)
cv2_imshow(edges)

def color_quantization(img, k):
# Transform the image
  data = np.float32(img).reshape((-1, 3))

# Determine criteria
  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)

# Implementing K-Means
  ret, label, center = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)   # k == the number of colors that we want to apply to the image uploaded
  center = np.uint8(center)
  result = center[label.flatten()]
  result = result.reshape(img.shape)
  return result

total_color = 9 # will determine the number of colors in the output picture.
img = color_quantization(img, total_color)
cv2_imshow(img)

blurred = cv2.bilateralFilter(img, d=7, sigmaColor=200,sigmaSpace=200) # reduce the noise in the image by using a bilateral filter to basically reduce sharpness and give a bit blurness
#blurred = cv2.bilateralFilter(img, d=15, sigmaColor=75,sigmaSpace=75) 
cv2_imshow(blurred)

"""d == Diameter of each pixel neighborhood.

sigmaColor == A larger value of the parameter means larger areas of semi-equal color.

sigmaSpace –A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough.
"""

cartoon = cv2.bitwise_and(blurred, blurred, mask=edges) # Now we combine the Edge Mask with the Colored Image

#cv2.stylization(cartoon, sigma_s = 150, sigma_r = 0.25)
cv2_imshow(cartoon)

"""Now we start playing around with the codes to create your own version of the cartoon effect. Besides adjusting the value in parameters that we used above, we also add another function from OpenCV to give special effects to your photos. There’s still a lot of things in the library that we can explore."""



